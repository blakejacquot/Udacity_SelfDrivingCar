{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Import packages\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_savename = 'model-checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1ca61aaca339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestore_model_for_continued_work\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_savename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_savename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mall_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_dir = './test_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It would be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the dataset?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Visualize the German Traffic Signs Dataset. This is open ended, some suggestions include: plotting traffic signs images, plotting the count of each sign, etc. Be creative!\n",
    "\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- features -> the images pixel values, (width, height, channels)\n",
    "- labels -> the label of the traffic sign\n",
    "- sizes -> the original width and height of the image, (width, height)\n",
    "- coords -> coordinates of a bounding box around the sign in the image, (x1, y1, x2, y2). Based the original image (not the resized version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/train.p'\n",
    "testing_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/test.p'\n",
    "\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42])\n",
      " \n",
      "X_train shape =  (39209, 32, 32, 3)\n",
      "y_train shape =  (39209,)\n",
      "X_test shape =  (12630, 32, 32, 3)\n",
      "y_test shape =  (12630,)\n",
      "Type of X_train =  <class 'numpy.ndarray'>\n",
      "Type of y_train =  <class 'numpy.ndarray'>\n",
      " \n",
      "Number of training examples = 39209\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### To start off let's do a basic data summary.\n",
    "labels = {}\n",
    "for el in y_train:\n",
    "    if el in labels.keys():\n",
    "        labels[el] += 1\n",
    "    else:\n",
    "        labels[el] = 1\n",
    "        \n",
    "print(labels.keys())\n",
    "\n",
    "# TODO: number of training examples\n",
    "n_train = len(y_train)\n",
    "\n",
    "# TODO: number of testing examples\n",
    "n_test = len(y_test)\n",
    "\n",
    "# TODO: what's the shape of an image?\n",
    "single_image = X_train[0][:][:][:]\n",
    "image_shape = single_image.shape\n",
    "\n",
    "# TODO: how many classes are in the dataset\n",
    "n_classes = len(labels.keys())\n",
    "\n",
    "print(' ')\n",
    "print('X_train shape = ', X_train.shape)\n",
    "print('y_train shape = ', y_train.shape)\n",
    "print('X_test shape = ', X_test.shape)\n",
    "print('y_test shape = ', y_test.shape)\n",
    "print(\"Type of X_train = \", type(X_train))\n",
    "print(\"Type of y_train = \", type(y_train))\n",
    "print(' ')\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Helper functions for data categorization and exploration\"\"\"\n",
    "\n",
    "def make_class_dict(y):\n",
    "    class_dict = {}\n",
    "    num_el = len(y)\n",
    "    for i in range(num_el):\n",
    "        curr_class = y[i]\n",
    "        if curr_class not in class_dict.keys():\n",
    "            class_dict[curr_class] = [i]\n",
    "        else:\n",
    "            pos_index = class_dict[curr_class]\n",
    "            pos_index.append(i)\n",
    "            class_dict[curr_class] = pos_index\n",
    "    return class_dict\n",
    "\n",
    "import random\n",
    "def plot_random(X, class_dict):\n",
    "    for curr_class in class_dict.keys():\n",
    "        pos_index = class_dict[curr_class]\n",
    "        len_index = len(pos_index)\n",
    "        i1 = random.randrange(len_index)\n",
    "        i2 = random.randrange(len_index)\n",
    "        i3 = random.randrange(len_index)\n",
    "        i4 = random.randrange(len_index)\n",
    "        i5 = random.randrange(len_index)\n",
    "        i6 = random.randrange(len_index)\n",
    "        i7 = random.randrange(len_index)\n",
    "        i8 = random.randrange(len_index)\n",
    "        i9 = random.randrange(len_index)\n",
    "        print('Current class = ' + str(curr_class))\n",
    "        index1 = pos_index[i1]\n",
    "        index2 = pos_index[i2]\n",
    "        index3 = pos_index[i3]\n",
    "        index4 = pos_index[i4]\n",
    "        index5 = pos_index[i5]\n",
    "        index6 = pos_index[i6]\n",
    "        index7 = pos_index[i7]\n",
    "        index8 = pos_index[i8]\n",
    "        index9 = pos_index[i9]\n",
    "\n",
    "        im1 = X[index1][:][:][:]\n",
    "        im2 = X[index2][:][:][:]\n",
    "        im3 = X[index3][:][:][:]\n",
    "        im4 = X[index4][:][:][:]\n",
    "        im5 = X[index5][:][:][:]\n",
    "        im6 = X[index6][:][:][:]\n",
    "        im7 = X[index7][:][:][:]\n",
    "        im8 = X[index8][:][:][:]\n",
    "        im9 = X[index9][:][:][:]\n",
    "     \n",
    "        plt.figure()\n",
    "        plt.subplot(331)\n",
    "        plt.imshow(im1)\n",
    "        plt.subplot(332)\n",
    "        plt.imshow(im2)\n",
    "        plt.subplot(333)\n",
    "        plt.imshow(im3)\n",
    "\n",
    "        plt.subplot(334)\n",
    "        plt.imshow(im4)\n",
    "        plt.subplot(335)\n",
    "        plt.imshow(im5)\n",
    "        plt.subplot(336)\n",
    "        plt.imshow(im6)\n",
    "        \n",
    "        plt.subplot(337)\n",
    "        plt.imshow(im7)\n",
    "        plt.subplot(338)\n",
    "        plt.imshow(im8)\n",
    "        plt.subplot(339)\n",
    "        plt.imshow(im9)\n",
    "        \n",
    "        plt.show() \n",
    "    plt.close(\"all\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Organize images into dictionaries\"\"\"\n",
    "class_dict_train = make_class_dict(y_train)\n",
    "class_dict_test = make_class_dict(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Display random images from training set\"\"\"\n",
    "plot_random(X_train, class_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Display random images from testing set\"\"\"\n",
    "plot_random(X_test, class_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 00 has 0210 entries\n",
      "Class 01 has 2220 entries\n",
      "Class 02 has 2250 entries\n",
      "Class 03 has 1410 entries\n",
      "Class 04 has 1980 entries\n",
      "Class 05 has 1860 entries\n",
      "Class 06 has 0420 entries\n",
      "Class 07 has 1440 entries\n",
      "Class 08 has 1410 entries\n",
      "Class 09 has 1470 entries\n",
      "Class 10 has 2010 entries\n",
      "Class 11 has 1320 entries\n",
      "Class 12 has 2100 entries\n",
      "Class 13 has 2160 entries\n",
      "Class 14 has 0780 entries\n",
      "Class 15 has 0630 entries\n",
      "Class 16 has 0420 entries\n",
      "Class 17 has 1110 entries\n",
      "Class 18 has 1200 entries\n",
      "Class 19 has 0210 entries\n",
      "Class 20 has 0360 entries\n",
      "Class 21 has 0330 entries\n",
      "Class 22 has 0390 entries\n",
      "Class 23 has 0510 entries\n",
      "Class 24 has 0270 entries\n",
      "Class 25 has 1500 entries\n",
      "Class 26 has 0600 entries\n",
      "Class 27 has 0240 entries\n",
      "Class 28 has 0540 entries\n",
      "Class 29 has 0270 entries\n",
      "Class 30 has 0450 entries\n",
      "Class 31 has 0780 entries\n",
      "Class 32 has 0240 entries\n",
      "Class 33 has 0689 entries\n",
      "Class 34 has 0420 entries\n",
      "Class 35 has 1200 entries\n",
      "Class 36 has 0390 entries\n",
      "Class 37 has 0210 entries\n",
      "Class 38 has 2070 entries\n",
      "Class 39 has 0300 entries\n",
      "Class 40 has 0360 entries\n",
      "Class 41 has 0240 entries\n",
      "Class 42 has 0240 entries\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU/7UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fa899b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = []\n",
    "num_entries = []\n",
    "for key in class_dict_train:\n",
    "    curr_num_entries = len(class_dict_train[key])\n",
    "    print('Class %02d has %04d entries' % (key,curr_num_entries))\n",
    "    classes.append(key)\n",
    "    num_entries.append(curr_num_entries)\n",
    "\n",
    "plt.bar(classes,num_entries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define helper functions for pre-processing\"\"\"\n",
    "\n",
    "def grayscale_singleimage(img):\n",
    "    \"\"\"Applies the Grayscale transform to single image.\n",
    "    \n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\n",
    "    \n",
    "    Args:\n",
    "        img: numpy array with dimensions [x,y]\n",
    "    Returns\n",
    "        Numpy array with dimensions [x, y]\n",
    "    \n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def grayscale_set(x):\n",
    "    print('Making grayscale')\n",
    "    x_shape = x.shape\n",
    "    num_el = x_shape[0]\n",
    "    ret_images = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "    for i in range(num_el):\n",
    "        curr_im = x[i,:,:,:]\n",
    "        ret_images[i,:,:] = grayscale_singleimage(curr_im)\n",
    "    return ret_images\n",
    "\n",
    "def normalize_set(x):\n",
    "    print('Normalizing data')\n",
    "    x_shape = x.shape\n",
    "    num_el = x_shape[0]\n",
    "    ret_images = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "    for i in range(num_el):\n",
    "        curr_im = x[i][:][:][:]\n",
    "        empty_im = np.ones((x_shape[1],x_shape[2]))\n",
    "        #proc_im = cv2.normalize(src=curr_im, dst=empty_im, alpha=0.1, beta=0.9, norm_type=cv2.NORM_MINMAX)\n",
    "        proc_im = cv2.normalize(src=curr_im, dst=empty_im, alpha=-1.,beta=1.,norm_type=cv2.NORM_MINMAX)\n",
    "        ret_images[i][:][:] = proc_im\n",
    "    return ret_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making grayscale\n",
      "Normalizing data\n",
      "Making grayscale\n",
      "Normalizing data\n",
      " \n",
      "Data info\n",
      "Shape of training data =  (39209, 32, 32)\n",
      "Shape of test data =  (12630, 32, 32)\n",
      "y_train shape =  (39209,)\n",
      "y_test shape =  (12630,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Preprocess data\"\"\"\n",
    "# Preprocess test data\n",
    "X_test_preproc = X_test\n",
    "X_test_preproc = grayscale_set(X_test_preproc)\n",
    "X_test_preproc = normalize_set(X_test_preproc)\n",
    "test_data = X_test_preproc\n",
    "\n",
    "# Preprocess training data\n",
    "X_train_preproc = X_train\n",
    "X_train_preproc = grayscale_set(X_train_preproc)\n",
    "X_train_preproc = normalize_set(X_train_preproc)\n",
    "train_data = X_train_preproc\n",
    "\n",
    "\"\"\"Print data info\"\"\"\n",
    "print(' ')\n",
    "print('Data info')\n",
    "print('Shape of training data = ', train_data.shape)\n",
    "print('Shape of test data = ', test_data.shape)\n",
    "\n",
    "train_labels = y_train\n",
    "test_labels = y_test\n",
    "print('y_train shape = ', y_train.shape)\n",
    "print('y_test shape = ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making one hot encoding\n",
      "Making one hot encoding\n"
     ]
    }
   ],
   "source": [
    "def make_one_hot_encoding(y, num_labels):\n",
    "    print('Making one hot encoding')\n",
    "    y_shape = y.shape\n",
    "    numel = y_shape[0]\n",
    "    ret_y = np.zeros((numel, num_labels))\n",
    "    for i in range(numel):\n",
    "        curr_label = y[i]\n",
    "        #print('Current label = ', curr_label)\n",
    "        curr_encoding = np.zeros(num_labels)\n",
    "        for j in range(num_labels):\n",
    "            if j == int(curr_label):\n",
    "                #print('Match!', j, curr_label)\n",
    "                curr_encoding[j] = 1.0\n",
    "        #print('Print one-hot encoding of label = ', curr_encoding)\n",
    "        ret_y[i] = curr_encoding\n",
    "    return ret_y\n",
    "\n",
    "\n",
    "\n",
    "train_labels = make_one_hot_encoding(y_train, 43)\n",
    "test_labels = make_one_hot_encoding(y_test, 43)\n",
    "\n",
    "\n",
    "# Must make the one-hot encoding float32 so values can be multiplied agains features in TensorFlow, which are float 32\n",
    "# This is maddening!!!!! I spent HOURS chasing this down. My values were initially in float64, which didn't work.\n",
    "# The model would train and not through warnings or errors, but accuracy never rose above 10%\n",
    "# After re-casting in float32, everything worked just fine.\n",
    "# Wish TensorFlow would at least give a warning if input is not in float32.\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding data\n",
      "Expanding data\n",
      "Train data shape =  (39209, 32, 32, 1)\n",
      "Test data shape =  (12630, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Expand data to have extra channel in order to be compatible with TensorFlow\"\"\"\n",
    "if len(train_data.shape) != 4:\n",
    "    print('Expanding data')\n",
    "    train_data = np.expand_dims(np.array(train_data),3)\n",
    "\n",
    "if len(test_data.shape) != 4:\n",
    "    print('Expanding data')\n",
    "    test_data = np.expand_dims(np.array(test_data),3)\n",
    "\n",
    "print('Train data shape = ', train_data.shape)\n",
    "print('Test data shape = ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "Preprocessing occurred in 4 steps: Grayscale -> Normalize -> One-hot encoding -> Expand dimensions.\n",
    "\n",
    "Grayscale: Convert each image in data set from color to grayscale. Note, this changes data from numpy array with dimensions (n, 32, 32, 3) to (n, 32, 32).\n",
    "\n",
    "Normalize: Change range of grayscale images from (0,256) to (-1.0, +1.0)\n",
    "\n",
    "One-hot encoding: Rather than integer or float labels for each data type (e.g. 1, 1.0, 3, 3.0), convert to a more binary representation so matrix math works (e.g. 3 becomes [0,0,1,0], 4 becomes [0,0,0,1]). The one-hot encoded version must by numpy array. This step is relatively simple. However there is a completely maddening part of this! TensorFlow expects the data type to be float32 so it can multiply by other float32 values internally. If you don't cast it as float32 and instead leave it cast as float64 (which many methods will do), TensorFlow will accept it and not through an error but all the optimization doesn't work well. I had my one-hot encoding initially cast as float64 and could never get accuracy to exceed 10% no matter how many epochs. When I recast as float32, I got better than 90% accuracy.\n",
    "\n",
    "This particular issue cost me many, many hours and isn't well documented. I will TensorFlow or Udacity would have been more proactive on this.\n",
    "\n",
    "Expand dimensions: TensorFlow expects color channels for images. So, it won't accept numpy arrays with dimensions (n, 32, 32). Expand this to (n, 32, 32, 1) so it works, even though the last dimension is meaningless in terms of information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape before validation split (39209, 32, 32, 1) (39209, 43)\n",
      "Train shape after validation split (37248, 32, 32, 1) (37248, 43)\n"
     ]
    }
   ],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\"\"\"Make a validation set from some of training data\"\"\"\n",
    "\n",
    "print('Train shape before validation split', train_data.shape, train_labels.shape)\n",
    "train_data, validation_data, train_labels, validation_labels = train_test_split(train_data, train_labels,test_size=0.05, random_state=101)\n",
    "print('Train shape after validation split', train_data.shape, train_labels.shape)\n",
    "\n",
    "## Save the data for easy access\n",
    "#pickle_file = 'traffic_sign_data.pickle'\n",
    "#if not os.path.isfile(pickle_file):\n",
    "#    print('Saving data to pickle file...')\n",
    "#    try:\n",
    "#        with open('traffic-signs-data.pickle', 'wb') as pfile:\n",
    "#            pickle.dump(\n",
    "#                {\n",
    "#                    'train_dataset': train_features,\n",
    "#                    'train_labels': train_labels,\n",
    "#                    'valid_dataset': valid_features,\n",
    "#                    'valid_labels': valid_labels,\n",
    "#                    'test_dataset': test_data,\n",
    "#                    'test_labels': test_labels,\n",
    "#                },\n",
    "#                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "#    except Exception as e:\n",
    "#        print('Unable to save data to', pickle_file, ':', e)\n",
    "#        raise\n",
    "#\n",
    "#print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing as percentage of whole = 0.243639\n",
      "Training as percentage of whole = 0.718532\n",
      "Validation as percentage of whole = 0.037829\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Report General statistics on training, testing, validation data sets\"\"\"\n",
    "# Want training, test split to be 80%, 20% of total data\n",
    "# Of the remaining training data, want training, validation split to be 80%, 20%\n",
    "\n",
    "num_train = train_labels.shape[0]\n",
    "num_test = test_labels.shape[0]\n",
    "num_validation = validation_labels.shape[0]\n",
    "total_samples = num_train + num_test + num_validation\n",
    "\n",
    "print('Testing as percentage of whole = %f' % (num_test/total_samples))\n",
    "print('Training as percentage of whole = %f' % (num_train/total_samples))\n",
    "print('Validation as percentage of whole = %f' % (num_validation/total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape =  (37248, 32, 32, 1)\n",
      "Validation data shape =  (1961, 32, 32, 1)\n",
      "Test data shape =  (12630, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape = ', train_data.shape)\n",
    "print('Validation data shape = ', validation_data.shape)\n",
    "print('Test data shape = ', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. If you generated additional data, why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "I left 'test' as it was imported, which is ~25% of total data. For the 'Training' set, I split off 5% of the data. The ideal split would be closer to 20% 'Test' and 80% 'Training'. Of the 'Training' data, split off 5% for 'Validation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"CNN helper functions\"\"\"\n",
    "\n",
    "n_input = 1024  # traffic sign data input (Shape: 32*32)\n",
    "n_classes = 43  # total number of traffic sign classes\n",
    "\n",
    "layer_width = {\n",
    "    'layer_1': 32,\n",
    "    'layer_2': 64,\n",
    "    'layer_3': 128,\n",
    "    'fully_connected': 512\n",
    "}\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'layer_1': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, 1, layer_width['layer_1']],stddev=1e-3)),\n",
    "    'layer_2': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_1'], layer_width['layer_2']],stddev=1e-3)),\n",
    "    'layer_3': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_2'], layer_width['layer_3']],stddev=1e-3)),\n",
    "    'fully_connected': tf.Variable(tf.truncated_normal(\n",
    "        [2048, layer_width['fully_connected']],stddev=1e-3)),\n",
    "    'out': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected'], n_classes],stddev=1e-3))\n",
    "}\n",
    "biases = {\n",
    "    'layer_1': tf.Variable(tf.zeros(layer_width['layer_1'])),\n",
    "    'layer_2': tf.Variable(tf.zeros(layer_width['layer_2'])),\n",
    "    'layer_3': tf.Variable(tf.zeros(layer_width['layer_3'])),\n",
    "    'fully_connected': tf.Variable(tf.zeros(layer_width['fully_connected'])),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.tanh(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Define neural network architecture\"\"\"\n",
    "def conv_net(x, weights, biases):\n",
    "    # Layer 1\n",
    "    conv1 = conv2d(x, weights['layer_1'], biases['layer_1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = conv2d(conv1, weights['layer_2'], biases['layer_2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = conv2d(conv2, weights['layer_3'], biases['layer_3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(\n",
    "        conv3,\n",
    "        [-1, weights['fully_connected'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(\n",
    "        tf.matmul(fc1, weights['fully_connected']),\n",
    "        biases['fully_connected'])\n",
    "    fc1 = tf.nn.tanh(fc1)\n",
    "\n",
    "    # Output Layer - class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37248, 32, 32, 1) (1961, 32, 32, 1) (12630, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 128 \n",
    "training_epochs = 2\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 32, 32,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "logits = conv_net(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#Save the model after training\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "#Save the model after training\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print(train_data.shape, validation_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving stats to file\n",
      "Loading stats from file\n",
      "Saving stats to file\n"
     ]
    }
   ],
   "source": [
    "# Set up variables for logging and displaying data\n",
    "time_per_training_epoch = []\n",
    "training_accuracy_validation = []\n",
    "training_accuracy_testing = []\n",
    "cost_list = []\n",
    "stat_filename = 'save.p'\n",
    "\n",
    "\"\"\"Initialize or load pickled file containing status data on training\"\"\"\n",
    "    \n",
    "def initialize_stat_file(stat_filename):\n",
    "    print('Saving stats to file')\n",
    "    data_to_save = {'time_per_training_epoch': time_per_training_epoch, \n",
    "                    'training_accuracy_validation': training_accuracy_validation, \n",
    "                    'cost_list': cost_list}\n",
    "    pickle.dump(data_to_save, open( stat_filename, \"wb\" ))\n",
    "\n",
    "def load_stats_from_file(stat_filename):\n",
    "    print('Loading stats from file')\n",
    "    data_to_save = pickle.load(open( stat_filename, \"rb\" ))\n",
    "    time_per_training_epoch = data_to_save['time_per_training_epoch']\n",
    "    training_accuracy_validation = data_to_save['training_accuracy_validation']\n",
    "    cost_list = data_to_save['cost_list']\n",
    "    \n",
    "def save_stats_to_file(stat_filename):\n",
    "    print('Saving stats to file')\n",
    "    data_to_save = {'time_per_training_epoch': time_per_training_epoch, \n",
    "                    'training_accuracy_validation': training_accuracy_validation, \n",
    "                    'cost_list': cost_list}\n",
    "    pickle.dump(data_to_save, open( stat_filename, \"wb\" ))\n",
    "\n",
    "def report_stats_from_file(stat_filename):\n",
    "    print('Reporting from file to make plot')\n",
    "    \n",
    "    \"\"\"Retrieve data\"\"\"\n",
    "    unpickled_data = pickle.load( open(stat_filename, \"rb\" ) )\n",
    "    time_per_training_epoch = unpickled_data['time_per_training_epoch']\n",
    "    training_accuracy_validation = unpickled_data['training_accuracy_validation']\n",
    "    cost_list = unpickled_data['cost_list']\n",
    "\n",
    "    \"\"\"Plot and save fig for time per training epoch\"\"\"\n",
    "    fig_savename = 'time_per_training_epoch.png'\n",
    "    fig = plt.figure()\n",
    "    curr_plot1 = plt.plot(range(len(time_per_training_epoch)), time_per_training_epoch, color = 'b')\n",
    "    plt.ylabel('Time per training epoch (sec)')\n",
    "    plt.title('Training time per epoch', fontsize = 10)\n",
    "    plt.show()\n",
    "    curr_dir = os.getcwd()\n",
    "    fig.savefig(fig_savename)\n",
    "    fig.clf()\n",
    "\n",
    "    \"\"\"Plot and save fig for cost\"\"\"\n",
    "    fig_savename = 'cost_list.png'\n",
    "    fig = plt.figure()\n",
    "    curr_plot1 = plt.plot(range(len(cost_list)), cost_list, color = 'b')\n",
    "    plt.ylabel('Cost_list')\n",
    "    plt.title('Cost_list', fontsize = 10)\n",
    "    plt.show()\n",
    "    curr_dir = os.getcwd()\n",
    "    fig.savefig(fig_savename)\n",
    "    fig.clf()\n",
    "\n",
    "    \"\"\"Plot and save fig for validation model accuracy\"\"\"\n",
    "    fig_savename = 'training_accuracy_validation.png'\n",
    "    fig = plt.figure()\n",
    "    curr_plot1 = plt.plot(range(len(training_accuracy_validation)), training_accuracy_validation, color = 'b')\n",
    "    plt.ylabel('Training accuracy validation')\n",
    "    plt.title('Training accuracy validation', fontsize = 10)\n",
    "    plt.show()\n",
    "    curr_dir = os.getcwd()\n",
    "    fig.savefig(fig_savename)\n",
    "    fig.clf()\n",
    "\n",
    "    print('Done reporting stats')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "logfile = 'log.txt'\n",
    "f = open(logfile,'w')\n",
    "f.write('Log file for training session\\n') # python will convert \\n to os.linesep\n",
    "f.close() # you can omit in most cases as the destructor will call it\n",
    "\n",
    "initialize_stat_file(stat_filename)\n",
    "load_stats_from_file(stat_filename)\n",
    "save_stats_to_file(stat_filename)\n",
    "#report_stats_from_file(stat_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_savename = 'model-checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to train\n",
      " \n",
      "Starting epoch 00\n",
      "Number of batches to process = 291\n",
      "Processing batches. Not yet saving.\n"
     ]
    }
   ],
   "source": [
    "restore_model_for_continued_work = 0\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    print('Beginning to train')\n",
    "    sess.run(init)\n",
    "    \n",
    "    \"\"\"Restore saved model for continued work\"\"\"\n",
    "    if restore_model_for_continued_work == 1:\n",
    "        print('Restoring model')\n",
    "        start_time_restore = time.time()\n",
    "        saver = tf.train.import_meta_graph('model-checkpoint.meta')\n",
    "        saver.restore(sess, 'model-checkpoint')\n",
    "        all_vars = tf.trainable_variables()\n",
    "        elapsed_time = time.time() - start_time_restore\n",
    "        print('Time to restore model (sec) = ', int(elapsed_time))\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        print(' ')\n",
    "        print('Starting epoch %02d' % epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        total_batch = int(math.ceil(len(train_data)/batch_size))\n",
    "        print ('Number of batches to process = %0000d' % total_batch)\n",
    "        with open(logfile, \"a\") as myfile:\n",
    "            str_to_write = 'Batches per epoch, batch size, total_samples in training set: '\n",
    "            str_to_write += str(total_batch) + ' ' + str(batch_size) +  ' ' + str(total_samples) + '\\n'\n",
    "            myfile.write(str_to_write)     \n",
    "        # Loop over all batches\n",
    "        print('Processing batches. Not yet saving.')\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_start = i * batch_size;\n",
    "            batch_x = train_data[batch_start:batch_start+batch_size]\n",
    "            batch_y = train_labels[batch_start:batch_start+batch_size]\n",
    "            #start = i * batch_size\n",
    "            #stop  = i * batch_size + batch_size\n",
    "            #batch_x = training_data[start:stop, :, :]\n",
    "            #batch_y = training_labels[start:stop]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)            \n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            #acc = 0\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            #acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            with open(logfile, \"a\") as myfile:\n",
    "                str_to_write = 'Minibatch accuracy (epoch, iteration, accuracy): ' + str(epoch) + ' ' + str(i) + ' ' + str(acc) + '\\n'\n",
    "                myfile.write(str_to_write)            \n",
    "        print('Done processing batches. Checking accuracy and logging epoch results')\n",
    "        # Display logs per epoch step\n",
    "        c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        accuracy_validation = sess.run(accuracy, feed_dict={x: validation_data, y: validation_labels})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c),\" validation accuracy=\",\"{:,.3f}\".format(va))\n",
    "        epoch_stop_time = time.time()\n",
    "        elapsed_time = epoch_stop_time - epoch_start_time\n",
    "        print('Time to process epoch = ', int(elapsed_time))\n",
    "\n",
    "        # Load stats, append, values, save, and report\n",
    "        load_stats_from_file(stat_filename)        \n",
    "        cost_list.append(c)        \n",
    "        time_per_training_epoch.append(int(elapsed_time))\n",
    "        training_accuracy_validation.append(accuracy_validation)                \n",
    "        save_stats_to_file(stat_filename)\n",
    "        report_stats_from_file(stat_filename)        \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Save model\n",
    "    save_path = saver.save(sess, model_savename)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    print(\"Accuracy:\",accuracy.eval({x: test_data, y: test_labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = './traffic-signs-data/train.p'\n",
    "testing_file = './traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To start off let's do a basic data summary.\n",
    "\n",
    "# TODO: number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: number of testing examples\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: what's the shape of an image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# TODO: how many classes are in the dataset\n",
    "n_classes = max(y_train) + 1\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define preprocessing functions\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def normalize_greyscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a=0.1\n",
    "    b=0.9\n",
    "    x_min=0.\n",
    "    x_max=255.\n",
    "    image_data=image_data.astype('float_')\n",
    "    #print('size is: ',image_data.size)\n",
    "    for n in np.nditer(image_data,op_flags=['readwrite']):\n",
    "        n[...] = a + (((n-x_min)*(b-a))/(x_max-x_min))\n",
    "    # ToDo: Implement Min-Max scaling for greyscale image data\n",
    "    return image_data\n",
    "\n",
    "def convert_to_grayscale_and_normalize(feature_set):\n",
    "    feature_set = [normalize_greyscale(grayscale(features)) for features in feature_set]\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "\n",
    "#convert data to greyscale\n",
    "X_train_norm = convert_to_grayscale_and_normalize(X_train)\n",
    "X_test_norm = convert_to_grayscale_and_normalize(X_test)\n",
    "print(X_train_norm[0])\n",
    "plt.imshow(X_train_norm[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to one-hot encode labels, then split training and testing sets and pickle data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Turn labels into numbers and apply One-Hot Encoding\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "train_labels = encoder.transform(y_train)\n",
    "test_labels = encoder.transform(y_test)\n",
    "\n",
    "# Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    X_train_norm,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "# Save the data for easy access\n",
    "pickle_file = 'traffic_sign_data.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('traffic-signs-data.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': X_test_norm,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the data\n",
    "pickle_file = 'traffic-signs-data.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define CNN Helper functions\n",
    "\n",
    "n_input = 1024  # traffic sign data input (Shape: 32*32)\n",
    "n_classes = 43  # total number of traffic sign classes\n",
    "\n",
    "layer_width = {\n",
    "    'layer_1': 32,\n",
    "    'layer_2': 64,\n",
    "    'layer_3': 128,\n",
    "    'fully_connected': 512\n",
    "}\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'layer_1': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, 1, layer_width['layer_1']],stddev=1e-3)),\n",
    "    'layer_2': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_1'], layer_width['layer_2']],stddev=1e-3)),\n",
    "    'layer_3': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_2'], layer_width['layer_3']],stddev=1e-3)),\n",
    "    'fully_connected': tf.Variable(tf.truncated_normal(\n",
    "        [2048, layer_width['fully_connected']],stddev=1e-3)),\n",
    "    'out': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected'], n_classes],stddev=1e-3))\n",
    "}\n",
    "biases = {\n",
    "    'layer_1': tf.Variable(tf.zeros(layer_width['layer_1'])),\n",
    "    'layer_2': tf.Variable(tf.zeros(layer_width['layer_2'])),\n",
    "    'layer_3': tf.Variable(tf.zeros(layer_width['layer_3'])),\n",
    "    'fully_connected': tf.Variable(tf.zeros(layer_width['fully_connected'])),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.tanh(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Neural Network Architecture\n",
    "\n",
    "def conv_net(x, weights, biases):\n",
    "    # Layer 1\n",
    "    conv1 = conv2d(x, weights['layer_1'], biases['layer_1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = conv2d(conv1, weights['layer_2'], biases['layer_2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = conv2d(conv2, weights['layer_3'], biases['layer_3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(\n",
    "        conv3,\n",
    "        [-1, weights['fully_connected'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(\n",
    "        tf.matmul(fc1, weights['fully_connected']),\n",
    "        biases['fully_connected'])\n",
    "    fc1 = tf.nn.tanh(fc1)\n",
    "\n",
    "    # Output Layer - class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Parameters\n",
    "batch_size = 128 \n",
    "training_epochs = 10 \n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 32, 32,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "logits = conv_net(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#Save the model after training\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "train_features = np.expand_dims(np.array(train_features),3)\n",
    "valid_features = np.expand_dims(np.array(valid_features),3)\n",
    "test_features = np.expand_dims(np.array(test_features),3)\n",
    "\n",
    "#Save the model after training\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(math.ceil(len(train_features)/batch_size))\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_start = i * batch_size;\n",
    "            batch_x = train_features[batch_start:batch_start+batch_size]\n",
    "            batch_y = train_labels[batch_start:batch_start+batch_size]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "        c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        va = sess.run(accuracy, feed_dict={x: valid_features, y: valid_labels})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c),\" validation accuracy=\",\"{:,.3f}\".format(va))\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    save_path = saver.save(sess, \"trained_model_2b.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    # Calculate accuracy\n",
    "    print(\"Accuracy:\",accuracy.eval({x: test_features, y: test_labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jupyter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import tensorflow\n",
    "print(cv2.__version__)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/train.p'\n",
    "testing_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/test.p'\n",
    "\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"To start off let's do a basic data summary.\"\"\"\n",
    "\n",
    "print('X_train shape = ', X_train.shape)\n",
    "print('y_train shape = ', y_train.shape)\n",
    "print('X_test shape = ', X_test.shape)\n",
    "print('y_test shape = ', y_test.shape)\n",
    "print(\"Type of X_train = \", type(X_train))\n",
    "print(\"Type of y_train = \", type(y_train))\n",
    "\n",
    "labels = {}\n",
    "for el in y_train:\n",
    "    if el in labels.keys():\n",
    "        labels[el] += 1\n",
    "    else:\n",
    "        labels[el] = 1\n",
    "        \n",
    "print(labels.keys())\n",
    "print(len(labels.keys()))\n",
    "\n",
    "# TODO: number of training examples\n",
    "n_train = len(y_train)\n",
    "\n",
    "# TODO: number of testing examples\n",
    "n_test = len(y_test)\n",
    "\n",
    "# TODO: what's the shape of an image?\n",
    "single_image = X_train[0][:][:][:]\n",
    "image_shape = single_image.shape\n",
    "\n",
    "# TODO: how many classes are in the dataset\n",
    "n_classes = len(labels.keys())\n",
    "\n",
    "print(' ')\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Helper functions for data categorization and exploration\"\"\"\n",
    "\n",
    "def make_class_dict(y):\n",
    "    class_dict = {}\n",
    "    num_el = len(y)\n",
    "    for i in range(num_el):\n",
    "        curr_class = y[i]\n",
    "        if curr_class not in class_dict.keys():\n",
    "            class_dict[curr_class] = [i]\n",
    "        else:\n",
    "            pos_index = class_dict[curr_class]\n",
    "            pos_index.append(i)\n",
    "            class_dict[curr_class] = pos_index\n",
    "    return class_dict\n",
    "\n",
    "\n",
    "import random\n",
    "def plot_random(X, class_dict):\n",
    "    for curr_class in class_dict.keys():\n",
    "        pos_index = class_dict[curr_class]\n",
    "        len_index = len(pos_index)\n",
    "        i1 = random.randrange(len_index)\n",
    "        i2 = random.randrange(len_index)\n",
    "        i3 = random.randrange(len_index)\n",
    "        i4 = random.randrange(len_index)\n",
    "        i5 = random.randrange(len_index)\n",
    "        i6 = random.randrange(len_index)\n",
    "        i7 = random.randrange(len_index)\n",
    "        i8 = random.randrange(len_index)\n",
    "        i9 = random.randrange(len_index)\n",
    "        print('Current class = ' + str(curr_class))\n",
    "        index1 = pos_index[i1]\n",
    "        index2 = pos_index[i2]\n",
    "        index3 = pos_index[i3]\n",
    "        index4 = pos_index[i4]\n",
    "        index5 = pos_index[i5]\n",
    "        index6 = pos_index[i6]\n",
    "        index7 = pos_index[i7]\n",
    "        index8 = pos_index[i8]\n",
    "        index9 = pos_index[i9]\n",
    "\n",
    "        im1 = X[index1][:][:][:]\n",
    "        im2 = X[index2][:][:][:]\n",
    "        im3 = X[index3][:][:][:]\n",
    "        im4 = X[index4][:][:][:]\n",
    "        im5 = X[index5][:][:][:]\n",
    "        im6 = X[index6][:][:][:]\n",
    "        im7 = X[index7][:][:][:]\n",
    "        im8 = X[index8][:][:][:]\n",
    "        im9 = X[index9][:][:][:]\n",
    "     \n",
    "        plt.figure()\n",
    "        plt.subplot(331)\n",
    "        plt.imshow(im1)\n",
    "        plt.subplot(332)\n",
    "        plt.imshow(im2)\n",
    "        plt.subplot(333)\n",
    "        plt.imshow(im3)\n",
    "\n",
    "        plt.subplot(334)\n",
    "        plt.imshow(im4)\n",
    "        plt.subplot(335)\n",
    "        plt.imshow(im5)\n",
    "        plt.subplot(336)\n",
    "        plt.imshow(im6)\n",
    "        \n",
    "        plt.subplot(337)\n",
    "        plt.imshow(im7)\n",
    "        plt.subplot(338)\n",
    "        plt.imshow(im8)\n",
    "        plt.subplot(339)\n",
    "        plt.imshow(im9)\n",
    "\n",
    "        \n",
    "        plt.show() \n",
    "    plt.close(\"all\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Organize images and display random ones from each class\"\"\"\n",
    "\n",
    "class_dict_train = make_class_dict(y_train)\n",
    "class_dict_test = make_class_dict(y_test)\n",
    "\n",
    "plot_random(X_train, class_dict_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce number of image types for faster training\n",
    "\n",
    "\n",
    "\"\"\"Load pickled data\"\"\"\n",
    "import pickle\n",
    "\n",
    "training_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/train.p'\n",
    "testing_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "class_dict_train = make_class_dict(y_train)\n",
    "class_dict_test = make_class_dict(y_test)\n",
    "\n",
    "labels_desired = [0, 1, 2]\n",
    "\n",
    "train_keys = class_dict_train.keys()\n",
    "test_keys = class_dict_test.keys()\n",
    "\n",
    "train_keep = []\n",
    "test_keep = []\n",
    "\n",
    "for label in labels_desired:\n",
    "    for key in train_keys:\n",
    "        if key == label:\n",
    "            train_keep += class_dict_train[key]\n",
    "    for key in test_keys:\n",
    "        if key == label:\n",
    "            test_keep += class_dict_test[key]\n",
    "\n",
    "shape_X_train = X_train.shape\n",
    "shape_X_test = X_test.shape\n",
    "X_train_keep = np.zeros((len(train_keep), shape_X_train[1], shape_X_train[2], shape_X_train[3]), 'uint8')\n",
    "X_test_keep = np.zeros((len(test_keep), shape_X_test[1], shape_X_test[2], shape_X_test[3]), 'uint8')\n",
    "y_train_keep = np.zeros(len(train_keep))\n",
    "y_test_keep = np.zeros(len(test_keep))\n",
    "print(X_train_keep.shape, y_train_keep.shape)\n",
    "curr_im = X_train[0,:,:,:]\n",
    "print('Current image shape = ', curr_im.shape)\n",
    "im1 = curr_im[:,:,0]\n",
    "im2 = curr_im[:,:,1]\n",
    "im3 = curr_im[:,:,2]\n",
    "print(np.mean(im1))\n",
    "print(np.mean(im2))\n",
    "print(np.mean(im3))\n",
    "\n",
    "im1 = X_train[0,:,:,:]\n",
    "\n",
    "\n",
    "for i in range(len(train_keep)):\n",
    "    curr_im = X_train[train_keep[i],:,:,:]\n",
    "    X_train_keep[i,:,:,:] = curr_im\n",
    "    stor_im = X_train_keep[i,:,:,:]\n",
    "    #print(np.mean(curr_im[:,:,0]))\n",
    "    #print(np.mean(curr_im[:,:,1]))\n",
    "    #print(np.mean(curr_im[:,:,2]))\n",
    "    if np.mean(stor_im[:,:,0]) != np.mean(curr_im[:,:,0]):\n",
    "        if np.mean(stor_im[:,:,1]) != np.mean(curr_im[:,:,1]):\n",
    "            if np.mean(stor_im[:,:,2]) != np.mean(curr_im[:,:,2]):\n",
    "                print('Fail')\n",
    "    y_train_keep[i] = y_train[train_keep[i]]\n",
    "    #print(' ')\n",
    "    #print('X_train shape, X_train_keep =', X_train.shape, X_train_keep.shape)\n",
    "    #print('y_train shape, y_train_keep shape = ', y_train.shape, y_train_keep.shape)\n",
    "    #print('curr_im, stor_im = ', curr_im.shape, stor_im.shape)\n",
    "    \n",
    "for i in range(len(test_keep)):\n",
    "    X_test_keep[i,:,:,:] = X_test[test_keep[i],:,:,:]\n",
    "    y_test_keep[i] = y_test[test_keep[i]]    \n",
    "\n",
    "\n",
    "# Retrain the dicts\n",
    "class_dict_train = make_class_dict(y_train_keep)\n",
    "class_dict_test = make_class_dict(y_test_keep)\n",
    "\n",
    "# Reassign variables\n",
    "X_train = X_train_keep\n",
    "X_test = X_test_keep\n",
    "y_train = y_train_keep\n",
    "y_test = y_test_keep\n",
    "\n",
    "curr_im = X_train[0,:,:,:]\n",
    "print('Currentish image shape = ', curr_im.shape)\n",
    "#im1 = curr_im[:,:,0]\n",
    "#im2 = curr_im[:,:,1]\n",
    "#im3 = curr_im[:,:,2]\n",
    "#print(np.mean(im1))\n",
    "#print(np.mean(im2))\n",
    "#print(np.mean(im3))\n",
    "\n",
    "im1 = X_train_keep[0,:,:,:]\n",
    "im2 = X_train[0,:,:,:]\n",
    "\n",
    "if im1.all() == im2.all():\n",
    "    print('match')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(im1)\n",
    "plt.subplot(122)\n",
    "plt.imshow(im2, cmap = 'gray')\n",
    "plt.show() \n",
    "plt.close(\"all\")\n",
    "print(' ')\n",
    "print('im1 shape, im2 shape = ', im1.shape, im2.shape)\n",
    "print(np.mean(im1[:,:,0]),np.mean(im1[:,:,1]),np.mean(im1[:,:,2]))\n",
    "print(np.mean(im2[:,:,0]),np.mean(im2[:,:,1]),np.mean(im2[:,:,2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Examine testing data\n",
    "\n",
    "plot_random(X_train, class_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine testing data\n",
    "plot_random(X_test, class_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%reset -f\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\"\"\"Import modules\"\"\"\n",
    "import jupyter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Load pickled data\"\"\"\n",
    "#import pickle\n",
    "\n",
    "#training_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/train.p'\n",
    "#testing_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/test.p'\n",
    "\n",
    "#with open(training_file, mode='rb') as f:\n",
    "#    train = pickle.load(f)\n",
    "#with open(testing_file, mode='rb') as f:\n",
    "#    test = pickle.load(f)\n",
    "    \n",
    "#X_train, y_train = train['features'], train['labels']\n",
    "#X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce number of image types for faster training\n",
    "\n",
    "\n",
    "\"\"\"Load pickled data\"\"\"\n",
    "import pickle\n",
    "\n",
    "training_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/train.p'\n",
    "testing_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "class_dict_train = make_class_dict(y_train)\n",
    "class_dict_test = make_class_dict(y_test)\n",
    "\n",
    "labels_desired = [0, 1, 2]\n",
    "\n",
    "train_keys = class_dict_train.keys()\n",
    "test_keys = class_dict_test.keys()\n",
    "\n",
    "train_keep = []\n",
    "test_keep = []\n",
    "\n",
    "for label in labels_desired:\n",
    "    for key in train_keys:\n",
    "        if key == label:\n",
    "            train_keep += class_dict_train[key]\n",
    "    for key in test_keys:\n",
    "        if key == label:\n",
    "            test_keep += class_dict_test[key]\n",
    "\n",
    "shape_X_train = X_train.shape\n",
    "shape_X_test = X_test.shape\n",
    "X_train_keep = np.empty((len(train_keep), shape_X_train[1], shape_X_train[2], shape_X_train[3]), 'uint8')\n",
    "X_test_keep = np.empty((len(test_keep), shape_X_test[1], shape_X_test[2], shape_X_test[3]), 'uint8')\n",
    "y_train_keep = np.empty(len(train_keep))\n",
    "y_test_keep = np.empty(len(test_keep))\n",
    "print(X_train_keep.shape, y_train_keep.shape)\n",
    "curr_im = X_train[0,:,:,:]\n",
    "print('Current image shape = ', curr_im.shape)\n",
    "im1 = curr_im[:,:,0]\n",
    "im2 = curr_im[:,:,1]\n",
    "im3 = curr_im[:,:,2]\n",
    "print(np.mean(im1))\n",
    "print(np.mean(im2))\n",
    "print(np.mean(im3))\n",
    "\n",
    "im1 = X_train[0,:,:,:]\n",
    "\n",
    "\n",
    "for i in range(len(train_keep)):\n",
    "    curr_im = X_train[train_keep[i],:,:,:]\n",
    "    X_train_keep[i,:,:,:] = curr_im\n",
    "    stor_im = X_train_keep[i,:,:,:]\n",
    "    #print(np.mean(curr_im[:,:,0]))\n",
    "    #print(np.mean(curr_im[:,:,1]))\n",
    "    #print(np.mean(curr_im[:,:,2]))\n",
    "    if np.mean(stor_im[:,:,0]) != np.mean(curr_im[:,:,0]):\n",
    "        if np.mean(stor_im[:,:,1]) != np.mean(curr_im[:,:,1]):\n",
    "            if np.mean(stor_im[:,:,2]) != np.mean(curr_im[:,:,2]):\n",
    "                print('Fail')\n",
    "    y_train_keep[i] = y_train[int(train_keep[i])]\n",
    "    #print(' ')\n",
    "    #print('X_train shape, X_train_keep =', X_train.shape, X_train_keep.shape)\n",
    "    #print('y_train shape, y_train_keep shape = ', y_train.shape, y_train_keep.shape)\n",
    "    #print('curr_im, stor_im = ', curr_im.shape, stor_im.shape)\n",
    "    \n",
    "for i in range(len(test_keep)):\n",
    "    X_test_keep[i,:,:,:] = X_test[test_keep[i],:,:,:]\n",
    "    y_test_keep[i] = y_test[int(test_keep[i])]    \n",
    "\n",
    "\n",
    "# Retrain the dicts\n",
    "class_dict_train = make_class_dict(y_train_keep)\n",
    "class_dict_test = make_class_dict(y_test_keep)\n",
    "\n",
    "# Reassign variables\n",
    "X_train = X_train_keep\n",
    "X_test = X_test_keep\n",
    "y_train = y_train_keep\n",
    "y_test = y_test_keep\n",
    "\n",
    "curr_im = X_train[0,:,:,:]\n",
    "print('Currentish image shape = ', curr_im.shape)\n",
    "#im1 = curr_im[:,:,0]\n",
    "#im2 = curr_im[:,:,1]\n",
    "#im3 = curr_im[:,:,2]\n",
    "#print(np.mean(im1))\n",
    "#print(np.mean(im2))\n",
    "#print(np.mean(im3))\n",
    "\n",
    "im1 = X_train_keep[0,:,:,:]\n",
    "im2 = X_train[0,:,:,:]\n",
    "\n",
    "if im1.all() == im2.all():\n",
    "    print('match')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(im1)\n",
    "plt.subplot(122)\n",
    "plt.imshow(im2, cmap = 'gray')\n",
    "plt.show() \n",
    "plt.close(\"all\")\n",
    "print(' ')\n",
    "print('im1 shape, im2 shape = ', im1.shape, im2.shape)\n",
    "print(np.mean(im1[:,:,0]),np.mean(im1[:,:,1]),np.mean(im1[:,:,2]))\n",
    "print(np.mean(im2[:,:,0]),np.mean(im2[:,:,1]),np.mean(im2[:,:,2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Define helper functions for pre-processing\"\"\"\n",
    "def make_gaussian_blur(x, kernel_size):\n",
    "    print('Making gaussian blur')\n",
    "    x_shape = x.shape\n",
    "    #print(x_shape)\n",
    "    num_el = x_shape[0]\n",
    "    ret_images = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "    #print(ret_images.shape)\n",
    "    for i in range(num_el):\n",
    "        curr_im = x[i][:][:][:]\n",
    "        ret_images[i][:][:] = gaussian_blur(curr_im, kernel_size)\n",
    "    return ret_images\n",
    "\n",
    "def crop_to_ROI(x, vertices):\n",
    "    x_shape = x.shape\n",
    "    #print(x_shape)\n",
    "    num_el = x_shape[0]\n",
    "    ret_images = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "    #print(ret_images.shape)\n",
    "    for i in range(num_el):\n",
    "        curr_im = x[i][:][:][:]\n",
    "        ret_images[i][:][:] = get_ROI(curr_im, vertices)\n",
    "    return ret_images\n",
    "\n",
    "def normalize(x):\n",
    "    print('Normalizing data')\n",
    "    x_shape = x.shape\n",
    "    #print(x_shape)\n",
    "    num_el = x_shape[0]\n",
    "    ret_images = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "    #print(ret_images.shape)\n",
    "    for i in range(num_el):\n",
    "        curr_im = x[i][:][:][:]\n",
    "        empty_im = np.ones((x_shape[1],x_shape[2]))\n",
    "        proc_im = cv2.normalize(curr_im, empty_im, -1.,1.,cv2.NORM_MINMAX)\n",
    "        ret_images[i][:][:] = proc_im\n",
    "    return ret_images\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    #print(img.shape)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def make_grayscale(x):\n",
    "    print('Making grayscale')\n",
    "    x_shape = x.shape\n",
    "    #print(x_shape)\n",
    "    num_el = x_shape[0]\n",
    "    ret_images = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "    #print(ret_images.shape)\n",
    "    for i in range(num_el):\n",
    "        curr_im = x[i,:,:,:]\n",
    "        #print(curr_im.shape)\n",
    "        ret_images[i,:,:] = grayscale(curr_im)\n",
    "    return ret_images\n",
    "\n",
    "#def randomize_set(x,y):\n",
    "#    numel = len(y)\n",
    "#    #print(type(x), type(y))\n",
    "#    #print(x.shape, y.shape)\n",
    "#    listicle = [[i] for i in range(numel)]\n",
    "#    random.shuffle(listicle)\n",
    "#    x_shape = x.shape\n",
    "#    y_shape = y.shape\n",
    "#    ret_x = np.ones((x_shape[0],x_shape[1],x_shape[2]))\n",
    "#    ret_y = np.ones((x_shape[0]))\n",
    "#    #print(ret_x.shape, ret_y.shape)\n",
    "#    for i in range(numel):\n",
    "#        index = listicle[i]\n",
    "#        curr_x = x[index,:,:]\n",
    "#        curr_y = y[index]\n",
    "#        ret_x[i,:,:] = curr_x\n",
    "#        ret_y[i] = curr_y\n",
    "#        #print(index)\n",
    "#    return(ret_x,ret_y)\n",
    "\n",
    "def make_one_hot_encoding(y, num_labels):\n",
    "    print('Making one hot encoding')\n",
    "    y_shape = y.shape\n",
    "    numel = y_shape[0]\n",
    "    ret_y = np.zeros((numel, num_labels))\n",
    "    for i in range(numel):\n",
    "        curr_label = y[i]\n",
    "        #print('Current label = ', curr_label)\n",
    "        curr_encoding = np.zeros(num_labels)\n",
    "        for j in range(num_labels):\n",
    "            if j == int(curr_label):\n",
    "                #print('Match!', j, curr_label)\n",
    "                curr_encoding[j] = 1.0\n",
    "        #print('Print one-hot encoding of label = ', curr_encoding)\n",
    "        ret_y[i] = curr_encoding\n",
    "    return ret_y\n",
    "\n",
    "def expand_x(x):\n",
    "    shape_x = x.shape\n",
    "    #print('Length is = ', len(shape_x))\n",
    "    if len(shape_x) == 3:\n",
    "        print('Expanding dataset to [num el, row, col, 1]')\n",
    "        #ret_x = np.empty((shape_x[0],shape_x[1],shape_x[2],1))\n",
    "        #ret_x[:,:,:,0] = x\n",
    "        #print(ret_x.shape)\n",
    "        #print('Example value = ', ret_x[0,0,0,0])\n",
    "        ret_x = np.expand_dims(x, axis=3)\n",
    "    return(ret_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Load and preprocess data\"\"\"\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "#training_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/train.p'\n",
    "#testing_file = '/Users/blakejacquot/Dropbox/MOOCs/Udacity_SelfDrivingCar/Term1/TrafficSignClassifier/traffic-signs-data/test.p'\n",
    "\n",
    "#with open(training_file, mode='rb') as f:\n",
    "#    train = pickle.load(f)\n",
    "#    with open(testing_file, mode='rb') as f:\n",
    "#        test = pickle.load(f)\n",
    "\n",
    "#X_train, y_train = train['features'], train['labels']\n",
    "#X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "\"\"\"Preprocess datasets\"\"\"\n",
    "print(X_test.shape)\n",
    "X_test_preproc = X_test\n",
    "X_test_preproc = make_grayscale(X_test_preproc)\n",
    "#X_test_preproc = make_gaussian_blur(X_test_preproc, 1)\n",
    "X_test_preproc = normalize(X_test_preproc)\n",
    "X_test_preproc = expand_x(X_test_preproc)\n",
    "#y_onehot_test = make_one_hot_encoding(y_test, 43)\n",
    "y_onehot_test = make_one_hot_encoding(y_test, 3)\n",
    "test_data = X_test_preproc\n",
    "test_labels = y_onehot_test\n",
    "\n",
    "\n",
    "X_train_preproc = X_train\n",
    "X_train_preproc = make_grayscale(X_train_preproc)\n",
    "#X_train_preproc = make_gaussian_blur(X_train_preproc, 1)\n",
    "X_train_preproc = normalize(X_train_preproc)\n",
    "X_train_preproc = expand_x(X_train_preproc)\n",
    "#y_onehot_train = make_one_hot_encoding(y_train, 43)\n",
    "y_onehot_train = make_one_hot_encoding(y_train, 3)\n",
    "training_data = X_train_preproc\n",
    "training_labels = y_onehot_train\n",
    "total_samples = len(training_labels)\n",
    "\n",
    "\"\"\"Print data info\"\"\"\n",
    "print(' ')\n",
    "print('Data info')\n",
    "print('Shape of training labels = ', training_labels.shape)\n",
    "print('Shape of training data = ', training_data.shape)\n",
    "print('Shape of test labels = ', test_labels.shape)\n",
    "print('Shape of test data = ', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_im = X_train_preproc[10,:,:]\n",
    "print(np.min(curr_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine preprocessed data\n",
    "\n",
    "plot_random(X_train_preproc, class_dict_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_random(X_test_preproc, class_dict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Examine pre-processed data\"\"\"\n",
    "      \n",
    "\n",
    "print('Plotting images and classes from test set')\n",
    "numel = len(test_labels)\n",
    "for i in range(3):\n",
    "    curr_index = random.randrange(numel)\n",
    "    curr_im = test_data[curr_index,:,:]\n",
    "    curr_im = np.squeeze(curr_im)\n",
    "    curr_class_int = y_test[curr_index]\n",
    "    curr_class_onehot = test_labels[curr_index]\n",
    "    \n",
    "    print('Current index = ' + str(curr_index))\n",
    "    print('Current image shape = ', curr_im.shape)\n",
    "    print('Current class in decimal = ' + str(curr_class_int))\n",
    "    print('Current class one hot encoded = ' + str(curr_class_onehot))\n",
    "    \n",
    "    plt.figure()    \n",
    "    plt.imshow(curr_im, cmap='gray')\n",
    "    plt.show()     \n",
    "    print(' ')\n",
    "plt.close(\"all\")    \n",
    "    \n",
    "print('************************************************')\n",
    "    \n",
    "print('Plotting images and classes from training set')\n",
    "numel = len(training_labels)\n",
    "for i in range(3):\n",
    "    curr_index = random.randrange(numel)\n",
    "    curr_im = training_data[curr_index,:,:]\n",
    "#    curr_im = np.squeeze(training_data[curr_index,:,:,0])\n",
    "    curr_class_int = y_train[curr_index]\n",
    "    curr_class_onehot = training_labels[curr_index]\n",
    "    print('Current index = ' + str(curr_index))\n",
    "    print('Current image shape = ', curr_im.shape)\n",
    "    print('Current class in decimal = ' + str(curr_class_int))\n",
    "    print('Current class one hot encoded = ' + str(curr_class_onehot))\n",
    "    plt.figure()    \n",
    "    #plt.imshow(curr_im, cmap='gray')\n",
    "    plt.imshow(curr_im, cmap='gray')\n",
    "    print(' ')\n",
    "    plt.show()     \n",
    "\n",
    "plt.close(\"all\")    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "***Grayscale***: Convert from RGB to grayscale. For instance the training data went from size (12630, 32, 32, 3) to (12630, 32, 32)\n",
    "\n",
    "***Gaussian blur***: Option. Did not use in final implementation.\n",
    "\n",
    "***Normalization***: Since original pixel values are 0 to 256, subtract 128 from  each pixel to center values around zero.\n",
    "\n",
    "***Randomize data***: In initial dataset, images are ordered according to type. Learning may look better if this is randomized.\n",
    "\n",
    "***One-hot encode the data***: Self explanatory.\n",
    "\n",
    "***Expand data dimension***: TensorFlow did not like the data in form (12630, 32, 32), so I had to expand a dimension for the color channel. The form for processing is (12630, 32, 32, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. If you generated additional data, why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "I used a training and validation set only (in my code the validation set is called 'test'). I understand the purpose of having the formal test set is to avoid overfitting caused by learning bleeding back into the training set through the human overlord.\n",
    "\n",
    "I did not generate additional data, though I thought about using transformations on the signs to put images in different orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the split happened above in the preprocessing section. I did not generate additional data and did not split into three sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Helper functions for machine learning\"\"\"\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x\n",
    "        W\n",
    "        b\n",
    "        strides\n",
    "    Returns:\n",
    "        TBD\n",
    "    \"\"\"\n",
    "    #x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    #x = tf.nn.bias_add(x, b)\n",
    "\n",
    "    #return tf.nn.tanh(x)\n",
    "    return tf.nn.relu6(tf.nn.bias_add(tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], \n",
    "                                                  padding='SAME'),b))\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x\n",
    "        k\n",
    "    Returns:\n",
    "        TBD\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    \"\"\"Make a model for the network\n",
    "    Args:\n",
    "        x:\n",
    "        weights:\n",
    "        biases:\n",
    "\n",
    "    Returns:\n",
    "        out:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #x = tf.reshape(x, [-1,32,32,3])\n",
    "    \n",
    "    # Layer 1\n",
    "    conv1 = conv2d(x, weights['layer_1'], biases['layer_1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    conv1 = tf.nn.dropout(conv1, dropout)\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = conv2d(conv1, weights['layer_2'], biases['layer_2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    conv2 = tf.nn.dropout(conv2, dropout)\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = conv2d(conv2, weights['layer_3'], biases['layer_3'])\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    conv3 = tf.nn.dropout(conv3, dropout)\n",
    "\n",
    "    # Layer 4\n",
    "    #conv4 = conv2d(conv3, weights['layer_4'], biases['layer_4'])\n",
    "    #conv4 = maxpool2d(conv4, k=2)\n",
    "    #conv4 = tf.nn.dropout(conv4, dropout)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input\n",
    "    #val = weights['fully_connected'].get_shape().as_list()[0]\n",
    "    #print('Val = ', val)\n",
    "    #print('Weights fully connected = ', weights['fully_connected'])\n",
    "    #print('Biases fully connected = ', biases['fully_connected'])\n",
    "    \n",
    "    fc1 = tf.reshape(conv3, [-1, weights['fully_connected'].get_shape().as_list()[0]])\n",
    "    #fc1 = tf.add(tf.matmul(fc1, weights['fully_connected']), biases['fully_connected'])\n",
    "    #fc1 = tf.nn.tanh(fc1)    \n",
    "    fc1 = tf.nn.relu6(tf.add(tf.matmul(fc1, weights['fully_connected']), biases['fully_connected']))\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout) # Apply Dropout\n",
    "\n",
    "    # Output Layer - class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Set model parameters\"\"\"\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "training_epochs = 200\n",
    "n_input = 1024  # Data input taps. 32 * 32 = 1024\n",
    "n_classes = 3  # Total classes 43\n",
    "num_channels = 1\n",
    "dropout = 0.5\n",
    "\n",
    "layer_width = {\n",
    "    'layer_1': 32, #100\n",
    "    'layer_2': 64, #150\n",
    "    'layer_3': 64, #64\n",
    "    #'layer_4': 256,\n",
    "    'fully_connected': 512 #512\n",
    "    }\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, layer_width['layer_1'] outputs\n",
    "    'layer_1': tf.Variable(tf.random_normal(\n",
    "        [3, 3, num_channels, layer_width['layer_1']])),\n",
    "    \n",
    "    # 5x5 conv, layer_width['layer_1'] inputs, layer_width['layer_2'] outputs\n",
    "    'layer_2': tf.Variable(tf.random_normal(\n",
    "        [4, 4, layer_width['layer_1'], layer_width['layer_2']])),\n",
    "    \n",
    "    # 5x5 conv, layer_width['layer_2'] inputs, layer_width['layer_3'] outputs\n",
    "    'layer_3': tf.Variable(tf.random_normal(\n",
    "        [3, 3, layer_width['layer_2'], layer_width['layer_3']])),\n",
    "\n",
    "    #'layer_4': tf.Variable(tf.random_normal(\n",
    "     #   [3, 3, layer_width['layer_3'], layer_width['layer_4']])),\n",
    "    \n",
    "    # fully connected, 1024 inputs, layer_width['fully_connected'] outputs\n",
    "    'fully_connected': tf.Variable(tf.random_normal(\n",
    "        [1024, layer_width['fully_connected']])),\n",
    "    \n",
    "    # output, layer_width['fully_connected'] inputs, n_classes outputs\n",
    "    'out': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected'], n_classes]))\n",
    "}\n",
    "\n",
    "print('Layer 1 output taps = ', layer_width['layer_1'])\n",
    "print('Layer 2 output taps = ', layer_width['layer_2'])\n",
    "print('Layer 3 output taps = ', layer_width['layer_3'])\n",
    "\n",
    "biases = {\n",
    "    'layer_1': tf.Variable(tf.zeros(layer_width['layer_1'])),\n",
    "    'layer_2': tf.Variable(tf.zeros(layer_width['layer_2'])),\n",
    "    'layer_3': tf.Variable(tf.zeros(layer_width['layer_3'])),\n",
    "    #'layer_4': tf.Variable(tf.zeros(layer_width['layer_4'])),\n",
    "    'fully_connected': tf.Variable(tf.zeros(layer_width['fully_connected'])),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 32, 32, num_channels])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Construct the model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate the model\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "   \n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Spot check the model\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() # Object to save and restore variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Flow control used to save out intermediate states\"\"\"\n",
    "\n",
    "# Flow control for statistics\n",
    "save_stats_to_file = 1\n",
    "load_stats_from_file = 1\n",
    "report_stats_from_file = 1\n",
    "initialize_stat_file = 1\n",
    "\n",
    "# Flow control for training\n",
    "restore_model_for_continued_work = 0\n",
    "train_model = 1\n",
    "check_model = 0\n",
    "\n",
    "# Initialize statistics variables\n",
    "time_per_training_epoch = []\n",
    "training_accuracy = []\n",
    "cost_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Initialize or load pickled file containing status data on training\"\"\"\n",
    "\n",
    "if initialize_stat_file == 1:\n",
    "    print('Saving stats to file')\n",
    "    data_to_save = {'time_per_training_epoch': time_per_training_epoch, 'training_accuracy': training_accuracy, 'cost_list': cost_list}\n",
    "    pickle.dump(data_to_save, open( \"save.p\", \"wb\" ))\n",
    "\n",
    "if load_stats_from_file == 1:\n",
    "    print('Loading stats from file')\n",
    "    data_to_save = pickle.load(open( \"save.p\", \"rb\" ))\n",
    "    time_per_training_epoch = data_to_save['time_per_training_epoch']\n",
    "    training_accuracy = data_to_save['training_accuracy']\n",
    "    cost_list = data_to_save['cost_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logfile = 'log.txt'\n",
    "f = open(logfile,'w')\n",
    "f.write('Log file for training session\\n') # python will convert \\n to os.linesep\n",
    "f.close() # you can omit in most cases as the destructor will call it\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    \"\"\"Restore saved model for continued work\"\"\"\n",
    "    if restore_model_for_continued_work == 1:\n",
    "        print('Restoring model')\n",
    "        start_time_restore = time.time()\n",
    "        saver = tf.train.import_meta_graph('model-checkpoint.meta')\n",
    "        saver.restore(sess, 'model-checkpoint')\n",
    "        all_vars = tf.trainable_variables()\n",
    "        elapsed_time = time.time() - start_time_restore\n",
    "        print('Time to restore model (sec) = ', int(elapsed_time))\n",
    "\n",
    "    \"\"\"Train model\"\"\"\n",
    "    if train_model == 1:\n",
    "        print('Training model')\n",
    "        for epoch in range(training_epochs):\n",
    "            print('Starting epoch = ', epoch)\n",
    "            start_time_train = time.time()\n",
    "            total_batch = int(total_samples/batch_size)\n",
    "            with open(logfile, \"a\") as myfile:\n",
    "                str_to_write = 'Batches per epoch, batch size, total_samples in training set: '\n",
    "                str_to_write += str(total_batch) + ' ' + str(batch_size) +  ' ' + str(total_samples) + '\\n'\n",
    "                myfile.write(str_to_write)            \n",
    "            \n",
    "            # Loop over all batches\n",
    "            print('Processing batches. Not yet saving.')\n",
    "            avg_cost = 0\n",
    "            for i in range(total_batch):\n",
    "                start = i * batch_size\n",
    "                stop  = i * batch_size + batch_size\n",
    "                batch_x = training_data[start:stop, :, :]\n",
    "                batch_y = training_labels[start:stop]\n",
    "                #print('Shape batch_x = ', batch_x.shape)\n",
    "                #print('Shape batch_y = ', batch_y.shape)\n",
    "                #print(optimizer)\n",
    "                \n",
    "                \n",
    "                #curr_im = training_data[stop,:,:]\n",
    "                #plt.figure()    \n",
    "                #plt.imshow(curr_im, cmap='gray')\n",
    "                #plt.show()\n",
    "                #print(training_labels[start])\n",
    "                \n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "                #print(sess.run(weights['out']))\n",
    "                #print(sess.run(biases))\n",
    "               \n",
    "                #prediction=tf.argmax(logits, 1)\n",
    "                #l = sess.run(tf.argmax(logits, 1), feed_dict={x:batch_x, y: batch_y, keep_prob: 1.})\n",
    "                #print(l) #actual labels for the minibatch\n",
    "                #best = sess.run(tf.argmax(y, 1), feed_dict={x:batch_x, y: batch_y, keep_prob: 1.})\n",
    "                #print(best) #predicted labels for the minibatch\n",
    "                \n",
    "                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "                # Calculate batch loss\n",
    "                #loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})               \n",
    "                #print(\"Minibatch accuracy:\", i, acc)\n",
    "                with open(logfile, \"a\") as myfile:\n",
    "                    str_to_write = 'Minibatch accuracy (epoch, iteration, accuracy): ' + str(epoch) + ' ' + str(i) + ' ' + str(acc) + '\\n'\n",
    "                    myfile.write(str_to_write)\n",
    "                #avg_cost += cost\n",
    "                \n",
    "            # Display logs per epoch step\n",
    "            c = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "            #c = avg_cost/total_batch\n",
    "\n",
    "            #print(type(c))\n",
    "            cost_list.append(c)\n",
    "\n",
    "            # Save model checkpoint\n",
    "            print('Saving session')\n",
    "            #saver.save(sess, 'model-checkpoint')\n",
    "\n",
    "            # Print info about the epoch\n",
    "            elapsed_time = time.time() - start_time_train\n",
    "            print('Time to process epoch (sec) = ', int(elapsed_time))\n",
    "            time_per_training_epoch.append(int(elapsed_time))\n",
    "            print(' ')\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "            \"\"\"Test model and report accuracy\"\"\"\n",
    "            print('Calculating Accuracy')\n",
    "            start_time_test_report = time.time()\n",
    "            ################################################################################\n",
    "            ###############################################################################\n",
    "            ################################################################################\n",
    "            # Previously, 'logits' was defined as: logits = conv_net(x, weights, biases)\n",
    "            # tf.argmax(logits, 1) is ...\n",
    "            # tf.argmax(y, 1) is ...\n",
    "            # tf.equal(x,y) the truth value of (x == y) element-wise.\n",
    "            # correct_prediction is tensor of type 'bool'\n",
    "            # tf.reduce_mean(input_tensor) computes the mean of elements across dimensions of a tensor\n",
    "            \n",
    "            instances_to_check = 1000\n",
    "            shape_data = test_data.shape\n",
    "            shape_labels = test_labels.shape\n",
    "            #print('Shape data =', shape_data)\n",
    "            #print('Shape labels = ', shape_labels)\n",
    "            #np.empty((shape_x[0],shape_x[1],shape_x[2],1))\n",
    "            data_to_check = np.zeros((instances_to_check, shape_data[1], shape_data[2],shape_data[3]))\n",
    "            labels_to_check = np.zeros((instances_to_check, shape_labels[1]))\n",
    "            \n",
    "            for k in range(instances_to_check):\n",
    "                ind = int(random.randrange(instances_to_check))\n",
    "                curr_data = training_data[ind,:,:,:]\n",
    "                curr_label = training_labels[ind,:]\n",
    "                data_to_check[k,:,:,:] = curr_data\n",
    "                labels_to_check[k,:] = curr_label\n",
    "            \n",
    "            # Calculate accuracy for test images\n",
    "            #accuracy_val = accuracy.eval({x: test_data, y: test_labels})\n",
    "            #accuracy_val = sess.run(accuracy, feed_dict={x: training_data, y: training_labels})      \n",
    "            accuracy_val = sess.run(accuracy, feed_dict={x: data_to_check, y: labels_to_check, keep_prob: 1.})      \n",
    "\n",
    "            print(\"Accuracy:\", accuracy_val)\n",
    "            ################################################################################\n",
    "            ################################################################################\n",
    "            ################################################################################\n",
    "\n",
    "            \n",
    "            elapsed_time = time.time() - start_time_test_report\n",
    "            training_accuracy.append(accuracy_val)\n",
    "            print('Time to test and report accuracy (sec) = ', int(elapsed_time))\n",
    "\n",
    "            if save_stats_to_file == 1:\n",
    "                print('Saving stats to file')\n",
    "                data_to_save = {'time_per_training_epoch': time_per_training_epoch, 'training_accuracy': training_accuracy, 'cost_list': cost_list}\n",
    "                pickle.dump(data_to_save, open( \"save.p\", \"wb\" ))\n",
    "\n",
    "            if report_stats_from_file == 1:\n",
    "                print('Reporting from file to make plot')\n",
    "                data_to_save = pickle.load( open( \"save.p\", \"rb\" ) )\n",
    "                time_per_training_epoch = data_to_save['time_per_training_epoch']\n",
    "                training_accuracy = data_to_save['training_accuracy']\n",
    "\n",
    "                \"\"\"Plot and save fig for time per training epoch\"\"\"\n",
    "                fig_savename = 'time_per_training_epoch.png'\n",
    "                fig = plt.figure()\n",
    "                curr_plot1 = plt.plot(range(len(time_per_training_epoch)), time_per_training_epoch, color = 'b')\n",
    "                plt.ylabel('Time per training epoch (sec)')\n",
    "                plt.title('Training time per epoch', fontsize = 10)\n",
    "                curr_dir = os.getcwd()\n",
    "                fig.savefig(fig_savename)\n",
    "                fig.clf()\n",
    "\n",
    "                \"\"\"Plot cost\"\"\"\n",
    "                fig_savename = 'cost.png'\n",
    "                fig = plt.figure()\n",
    "                curr_plot1 = plt.plot(range(len(cost_list)), cost_list, color = 'b')\n",
    "                plt.ylabel('Cost')\n",
    "                plt.title('Cost', fontsize = 10)\n",
    "                curr_dir = os.getcwd()\n",
    "                fig.savefig(fig_savename)\n",
    "                fig.clf()\n",
    "\n",
    "                \"\"\"Plot and save fig for model accuracy\"\"\"\n",
    "                fig_savename = 'training_accuracy.png'\n",
    "                fig = plt.figure()\n",
    "                curr_plot1 = plt.plot(range(len(training_accuracy)), training_accuracy, color = 'b')\n",
    "                plt.ylabel('Training accuracy')\n",
    "                plt.title('Training accuracy', fontsize = 10)\n",
    "                curr_dir = os.getcwd()\n",
    "                fig.savefig(fig_savename)\n",
    "                fig.clf()\n",
    "\n",
    "\n",
    "                print('Done reporting stats')\n",
    "                plt.close(\"all\")\n",
    "\n",
    "\n",
    "        print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Check model\"\"\"\n",
    "if check_model == 1:\n",
    "    print('Checking the model')\n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(init)\n",
    "\n",
    "        # Restore model\n",
    "        if restore_model_for_continued_work == 1:\n",
    "            print('Restoring model')\n",
    "            start_time_restore = time.time()\n",
    "            saver = tf.train.import_meta_graph('model-checkpoint.meta')\n",
    "            saver.restore(sess, 'model-checkpoint')\n",
    "            all_vars = tf.trainable_variables()\n",
    "            elapsed_time = time.time() - start_time_restore\n",
    "            print('Time to restore model (sec) = ', int(elapsed_time))\n",
    "            \n",
    "            \n",
    "## Construct the model\n",
    "#logits = conv_net(x, weights, biases)\n",
    "\n",
    "## Define loss and optimizer\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "#        .minimize(cost)            \n",
    "            \n",
    "## Evaluate the model\n",
    "           \n",
    "\n",
    "            \n",
    "        # Get image and label\n",
    "        print(type(test_data))\n",
    "        print(type(test_labels))\n",
    "        print(test_data.shape, test_labels.shape)\n",
    "        temp_data = test_data[0:1,:,:,:]\n",
    "        temp_labels = test_labels[0:1,:]\n",
    "        \n",
    "        # See if prediction is correct\n",
    "        most_likely_label_for_input = tf.argmax(logits, 1)\n",
    "        actual_label = tf.argmax(y, 1)\n",
    "        print('Most likely label = ', most_likely_label_for_input)\n",
    "        print('Actual label = ', actual_label)\n",
    "        correct_prediction = tf.equal(most_likely_label_for_input, actual_label) # Returns list of Booleans.\n",
    "        \n",
    "        # Determine what fraction of predictions are correct\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # returns reduced tensor\n",
    "        \n",
    "        print(type(correct_prediction))\n",
    "        print(type(accuracy))\n",
    "        #accuracy_val = sess.run(accuracy, feed_dict={x: temp_data, y: temp_labels})      \n",
    "        accuracy_val = accuracy.eval({x: temp_data, y: temp_labels})\n",
    "        print(type(accuracy_val))\n",
    "        print(\"Accuracy:\", accuracy_val)   \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Infer label from image\n",
    "        \n",
    "        # Compare inferred label to actual label\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
