	# Launch the graph
	with tf.Session() as sess:
		sess.run(init)

		# Training cycle
		print('Starting first epoch')
		for epoch in range(training_epochs):
			start_time = time.time()
			total_batch = int(total_samples/batch_size)

			if os.path.isfile(save_file):
				print('Restoring file')
	        	# Restore model checkpoint
				saver = tf.train.import_meta_graph('model-checkpoint.meta')
				saver.restore(sess, save_path)




			#sys.exit()

			# Loop over all batches
			for i in range(total_batch):
				batch_x = training_data[i*batch_size:i*batch_size+batch_size,:,:]
				batch_y = training_labels[i*batch_size:i*batch_size+batch_size]

				# Run optimization op (backprop) and cost op (to get loss value)
				sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})

			# Display logs per epoch step
			c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})

            # Save model checkpoint
			saver.save(sess, 'model-checkpoint')
            # `save` method will call `export_meta_graph` implicitly.
            # you will get 2 saved files:my-model.ckpt and my-model.ckpt.meta


			# Print info about the epoch
			print("Epoch:", '%04d' % (epoch+1), "cost=", "{:.9f}".format(c))
			elapsed_time = time.time() - start_time
			print('Time for last epoch (sec) = ', int(elapsed_time))
			print(' ')

		print("Optimization Finished!")

		# Test model
		correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))

		# Calculate accuracy
		accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
		print(
			"Accuracy:",
			accuracy.eval({x: test_data, y: test_labels}))
